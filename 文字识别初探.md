---
title: 文字识别初探
date: 2016-10-08 11:57:23
tags:
 - 文字识别
 - tesseract
 - OCR
 - 开源
---

随着中国互联网对广告的审核越来越严格，日常投放运营过程中，渠道对资质文件和创意的要求越来越高，如营业执照、身份证等。我们需要花费大量的人力成本对这些文件的属性进行文本描述，如营业主题，姓名，生日等。有没有一种方案对文件进行快速的描述，减少人力成本？

另一方面，这个需求是具有可扩展性的。图形学方向上的人工智能，是建立在图像识别基础上。计算广告日后必然和图形学和人工智能强关联，正好探索这个方向的可行性，并把该躺的坑给躺一遍。

作为一个产品，会先对一些开源的框架以及开放的 API做基本的可行性调研。
随手Google之后，决定本地使用[Tesseract](https://github.com/tesseract-ocr/tesseract)观察目前OCR（Optical Character Recognition）引擎效果。

[#reference-浅谈OCR之Tesseract](http://www.cnblogs.com/brooks-dotnet/archive/2010/10/05/1844203.html)
[#reference-Tesseract:安装与命令行使用](http://www.zmonster.me/2015/04/17/tesseract-install-usage.html)

# 安装

通过homebrew[安装](https://github.com/tesseract-ocr/tesseract#installing-tesseract)到本地`/usr/local/Cellar` [#reference-homebrew](http://brew.sh/index_zh-cn.html)
> brew install tesseract

# 直接识别

尝试识别如下图片：
![文字识别原图](http://upload-images.jianshu.io/upload_images/544981-da018847ebb20a99.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

执行`tesseract <%path_to_pic> stdout`后得到。

![直接识别后结果](http://upload-images.jianshu.io/upload_images/544981-7940772e8e5a20c7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到英文和数字的识别正确率很高，中文识别这么不靠谱？显然不是，不同语言的文字识别机制可能不一样。Google后发现需要指定语言后识别。由于我们的目标是中文识别，**必须解决语言包问题**。当然可以自行选择自己愿意安装的语言包，但最方便的是支持所有available的语言包。
重新执行`brew install tesseract --all-languages` 安装所有语言包。

[#reference-Chinese OCR](https://blog.philippklaus.de/2011/01/chinese-ocr/)
[#reference-利用Tesseract图片文字识别初探](https://tonydeng.github.io/2016/07/28/on-the-use-of-tesseract-picture-text-recognition/)
[#reference-ocr markdown](https://gist.github.com/henrik/1967035)

现在我们执行`tesseract --list-langs`，可以看到
> $ tesseract --list-langs
List of available languages (107):
...
chi_sim
chi_tra
...

简繁体的中文识别目前都已经支持。由于是大陆环境，我们将主要是用简体中文语言包进行识别。

# 中文识别

再次通过语言包尝试识别，执行`tesseract <%path_to_pic> stdout -l chi_sim`

![中文识别后结果](http://upload-images.jianshu.io/upload_images/544981-a53b4c3c27dfc4f3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

显然，准确率大大提高。虽然如此，可用性还是不足以支撑生产环境的需求。

# 分块后中文识别

会不会因为单词识别文本太多，导致识别不够准确呢？毕竟即使是人，当看到一大块文本的时候也感到头晕目眩。我们把原文本一分为三后，再次识别。

![文字识别原图1](http://upload-images.jianshu.io/upload_images/544981-22ec19a01e4bdc81.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![文字识别原图3](http://upload-images.jianshu.io/upload_images/544981-37cb90f52b93ce3d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![文字识别原图2](http://upload-images.jianshu.io/upload_images/544981-3980f522eedf4222.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
 
 ![分块后中文识别结果](http://upload-images.jianshu.io/upload_images/544981-e207723babdee53e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

显然准确率有所提高。虽然也还是无法使用:(
 
## 如何分块

那么我们应该如何对一张图片中的文本作分块呢？简单来说，就是利用[opencv](http://opencv.org)，看出来白色的色块 然后定位做文字识别。

![Paste_Image.png](http://upload-images.jianshu.io/upload_images/544981-cdddb73f504d1001.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

#后续探索

后续可以进行探索的方向：

 - [OCR 中文识别用哪种软件识别率比较高？](https://www.zhihu.com/question/19593313)
 - [image++api](http://www.imageplusplus.com/#demo)
 - 如何更合适地对图片的文本区域分块
 - 根据图片直接判断语言

原文发布于：